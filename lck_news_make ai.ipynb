{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y0ydTk_Ncpf",
        "outputId": "70474033-5e22-44f9-b611-687a05bf982a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install pandas\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJggMpc4Npo-",
        "outputId": "233c22ed-bd94-49a6-85ab-73abece20c17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/77.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = 'sk-proj-Xr54jo7ABwRtNSu0GdxNT3BlbkFJYzFwotbee0FakwIJlFLl'  # 여기에 실제 API 키를 입력하세요\n",
        "\n",
        "# 카테고리와 세부 카테고리 매핑\n",
        "categories = {\n",
        "    1: ('정치', '100'),\n",
        "    2: ('경제', '101'),\n",
        "    3: ('사회', '102'),\n",
        "    4: ('생활/문화', '103'),\n",
        "    5: ('세계', '104'),\n",
        "    6: ('IT/과학', '105')\n",
        "}\n",
        "\n",
        "subcategories = {\n",
        "    '정치': {\n",
        "        1: ('대통령실', '264'),\n",
        "        2: ('국회/정당', '265'),\n",
        "        3: ('북한', '268'),\n",
        "        4: ('행정', '266'),\n",
        "        5: ('국방/외교', '267'),\n",
        "        6: ('정치일반', '269')\n",
        "    },\n",
        "    '경제': {\n",
        "        1: ('금융', '259'),\n",
        "        2: ('증권', '258'),\n",
        "        3: ('산업/재계', '261'),\n",
        "        4: ('중기/벤처', '771'),\n",
        "        5: ('부동산', '260'),\n",
        "        6: ('글로벌 경제', '262'),\n",
        "        7: ('생활경제', '310'),\n",
        "        8: ('경제일반', '263')\n",
        "    },\n",
        "    '사회': {\n",
        "        1: ('사건사고', '249'),\n",
        "        2: ('교육', '250'),\n",
        "        3: ('노동', '251'),\n",
        "        4: ('언론', '254'),\n",
        "        5: ('환경', '252'),\n",
        "        6: ('인권/복지', '59b'),\n",
        "        7: ('식품/의료', '255'),\n",
        "        8: ('지역', '256'),\n",
        "        9: ('인물', '276'),\n",
        "        10: ('사회일반', '257')\n",
        "    },\n",
        "    '생활/문화': {\n",
        "        1: ('건강정보', '241'),\n",
        "        2: ('자동차/시승기', '239'),\n",
        "        3: ('도로/교통', '240'),\n",
        "        4: ('여행/레저', '237'),\n",
        "        5: ('음식/맛집', '238'),\n",
        "        6: ('패션/뷰티', '376'),\n",
        "        7: ('공연/전시', '242'),\n",
        "        8: ('책', '243'),\n",
        "        9: ('종교', '244'),\n",
        "        10: ('날씨', '248'),\n",
        "        11: ('생활문화 일반', '245')\n",
        "    },\n",
        "    '세계': {\n",
        "        1: ('아시아/호주', '231'),\n",
        "        2: ('미국/중남미', '232'),\n",
        "        3: ('유럽', '233'),\n",
        "        4: ('중동/아프리카', '234'),\n",
        "        5: ('세계 일반', '322')\n",
        "    },\n",
        "    'IT/과학': {\n",
        "        1: ('모바일', '731'),\n",
        "        2: ('인터넷/SNS', '226'),\n",
        "        3: ('통신/뉴미디어', '227'),\n",
        "        4: ('IT 일반', '230'),\n",
        "        5: ('보안/해킹', '732'),\n",
        "        6: ('컴퓨터', '283'),\n",
        "        7: ('게임/리뷰', '229'),\n",
        "        8: ('과학 일반', '228')\n",
        "    }\n",
        "}\n",
        "\n",
        "# 카테고리 선택\n",
        "print(\"카테고리를 선택하세요:\")\n",
        "for key, (name, code) in categories.items():\n",
        "    print(f\"{key}. {name}\")\n",
        "\n",
        "category_choice = int(input(\"카테고리 번호: \"))\n",
        "category_name, category_code = categories[category_choice]\n",
        "\n",
        "# 세부 카테고리 선택\n",
        "print(f\"{category_name}의 세부 카테고리를 선택하세요:\")\n",
        "for key, (name, code) in subcategories[category_name].items():\n",
        "    print(f\"{key}. {name}\")\n",
        "\n",
        "subcategory_choice = int(input(\"세부 카테고리 번호: \"))\n",
        "subcategory_name, subcategory_code = subcategories[category_name][subcategory_choice]\n",
        "\n",
        "# URL 생성\n",
        "url = f'https://news.naver.com/breakingnews/section/{category_code}/{subcategory_code}'\n",
        "header = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "print(url)\n",
        "\n",
        "# HTTP GET 요청\n",
        "html = requests.get(url, headers=header)\n",
        "\n",
        "# HTML 파싱\n",
        "soup = BeautifulSoup(html.text, 'html.parser')\n",
        "\n",
        "# 뉴스 제목과 링크를 저장할 리스트\n",
        "news_list = []\n",
        "\n",
        "# 첫 번째 섹션 뉴스 제목과 링크 추출\n",
        "for i in range(1, 7):\n",
        "    elements = soup.select(f'#newsct > div.section_latest > div > div.section_latest_article._CONTENT_LIST._PERSIST_META > div:nth-child(1) > ul > li:nth-of-type({i}) > div > div > div.sa_text > a')\n",
        "    if elements:\n",
        "        title = elements[0].select_one('strong').text.strip()\n",
        "        link = elements[0].get('href')\n",
        "        news_list.append((title, link))\n",
        "\n",
        "def extract_news_content(url):\n",
        "    html = requests.get(url, headers=header)\n",
        "    soup = BeautifulSoup(html.text, 'html.parser')\n",
        "    content_div = soup.select_one('#dic_area')\n",
        "    if content_div:\n",
        "        return content_div.text.strip()\n",
        "    else:\n",
        "        return \"본문을 찾을 수 없습니다.\"\n",
        "\n",
        "# 뉴스 본문 요약 함수 (한글)\n",
        "def summarize_text(text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"당신은 도움이 되는 조수입니다.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"다음 기사를 요약해 주세요:\\n\\n{text}\\n\\n요약:\"}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.5\n",
        "    )\n",
        "    summary = response['choices'][0]['message']['content'].strip()\n",
        "    return summary\n",
        "\n",
        "# 뉴스 제목 생성 함수 (한글)\n",
        "def generate_title(text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"당신은 도움이 되는 조수입니다.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"다음 기사를 바탕으로 제목을 생성해 주세요:\\n\\n{text}\\n\\n제목:\"}\n",
        "        ],\n",
        "        max_tokens=50,\n",
        "        temperature=0.5\n",
        "    )\n",
        "    title = response['choices'][0]['message']['content'].strip()\n",
        "    return title\n",
        "\n",
        "# 뉴스 데이터를 저장할 리스트\n",
        "data = []\n",
        "\n",
        "# 추출된 뉴스 제목, 링크와 본문 저장\n",
        "for title, link in news_list:\n",
        "    content = extract_news_content(link)\n",
        "    if content != \"본문을 찾을 수 없습니다.\" and content.strip() != \"\":\n",
        "        summary = summarize_text(content)\n",
        "        generated_title = generate_title(content)\n",
        "    else:\n",
        "        summary = \"요약을 할 수 없습니다.\"\n",
        "        generated_title = \"제목을 생성할 수 없습니다.\"\n",
        "    data.append({'원본 제목': title, '링크': link, '본문': content, '본문 요약': summary, '생성된 제목': generated_title})\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# CSV 파일로 저장\n",
        "csv_name = f'news_{category_code}_{subcategory_code}.csv'\n",
        "df.to_csv(csv_name, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"뉴스 데이터를 {csv_name} 파일로 저장했습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzn6SUULNvD9",
        "outputId": "8a547421-e3e2-4eea-ac23-018940e24b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "카테고리를 선택하세요:\n",
            "1. 정치\n",
            "2. 경제\n",
            "3. 사회\n",
            "4. 생활/문화\n",
            "5. 세계\n",
            "6. IT/과학\n",
            "카테고리 번호: 6\n",
            "IT/과학의 세부 카테고리를 선택하세요:\n",
            "1. 모바일\n",
            "2. 인터넷/SNS\n",
            "3. 통신/뉴미디어\n",
            "4. IT 일반\n",
            "5. 보안/해킹\n",
            "6. 컴퓨터\n",
            "7. 게임/리뷰\n",
            "8. 과학 일반\n",
            "세부 카테고리 번호: 1\n",
            "https://news.naver.com/breakingnews/section/105/731\n"
          ]
        }
      ]
    }
  ]
}